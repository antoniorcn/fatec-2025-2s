{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4f6b14a-36a2-4d26-b989-6de4414071ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4f93b08-3039-466f-a255-fe3e7e975b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "860d69c7-4d0c-4ccf-adca-e9dcd104a819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32b36ab7-0df0-4cc8-99b8-1b6879865047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "539d29c3-1613-449e-89fe-2614af60c6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import CategoryEncoding, Input, Dense, StringLookup, Embedding, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "155acd70-8edb-4636-bda1-73b37aeb9016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk    \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8f0f8e8-b7f9-4642-b273-631d0894663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fd0fc9f-124a-4957-80d5-3d2b418912fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54e4b871-b199-4ec7-9271-9d80fd2ce236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8a35fe2-114b-4fca-a031-d44acc978efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') # Necessário para word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2cacb76-4cf4-4ed0-9e55-a6627486e461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ConversaA</th>\n",
       "      <th>ConversaB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi, how are you doing?</td>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "      <td>i've been great. what about you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i've been great. what about you?</td>\n",
       "      <td>i've been good. i'm in school right now.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             ConversaA  \\\n",
       "0               hi, how are you doing?   \n",
       "1        i'm fine. how about yourself?   \n",
       "2  i'm pretty good. thanks for asking.   \n",
       "3    no problem. so how have you been?   \n",
       "4     i've been great. what about you?   \n",
       "\n",
       "                                  ConversaB  \n",
       "0             i'm fine. how about yourself?  \n",
       "1       i'm pretty good. thanks for asking.  \n",
       "2         no problem. so how have you been?  \n",
       "3          i've been great. what about you?  \n",
       "4  i've been good. i'm in school right now.  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../dados/nlp/dialogs.txt\", encoding=\"utf-8\", sep=\"\\t\", header=None, names=[\"ConversaA\", \"ConversaB\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "162dd565-1395-41a8-9a44-eecc43b15595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpar_texto( texto ):\n",
    "    translator = str.maketrans('—’', '  ', punctuation)\n",
    "    texto_limpo = texto.lower().translate( translator )\n",
    "    return \"<BOS> \" + texto_limpo + \" <EOS>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff341c65-220a-4572-ac3a-cd06508206a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ConversaALimpa\"] = df[\"ConversaA\"].apply(limpar_texto)\n",
    "df[\"ConversaBLimpa\"] = df[\"ConversaB\"].apply(limpar_texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fea26889-0ad9-44b6-b575-38856c8273b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<OOV>', 1), ('<BOS>', 2), ('<EOS>', 3), ('i', 4), ('you', 5)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <BOS> - <Begin Of Sentence>\n",
    "# <EOS> - <End Of Sentence>\n",
    "# <OOV> - <Out Of Vocabulary>\n",
    "\n",
    "lista_final = list(df[\"ConversaALimpa\"]) + list(df[\"ConversaBLimpa\"])\n",
    "tokenizer = Tokenizer(oov_token=\"<OOV>\", filters=\"\", lower=False) # OOV = Out Of Vocabulary\n",
    "tokenizer.fit_on_texts( lista_final )\n",
    "vocabulario = tokenizer.word_index\n",
    "list(vocabulario.items())[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "680b8605-862f-4634-bf18-39d04d162f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_conversa_a = tokenizer.texts_to_sequences( df[\"ConversaALimpa\"] )\n",
    "tokens_conversa_b = tokenizer.texts_to_sequences( df[\"ConversaBLimpa\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d238962c-c389-4c26-b191-b670c6360e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                <BOS> hi how are you doing <EOS>\n",
      "1          <BOS> im fine how about yourself <EOS>\n",
      "2    <BOS> im pretty good thanks for asking <EOS>\n",
      "3     <BOS> no problem so how have you been <EOS>\n",
      "4       <BOS> ive been great what about you <EOS>\n",
      "Name: ConversaALimpa, dtype: object\n",
      "[[2, 1515, 39, 17, 5, 177, 3], [2, 34, 606, 39, 36, 556, 3], [2, 34, 159, 48, 250, 26, 491, 3], [2, 31, 173, 23, 39, 16, 5, 102, 3], [2, 103, 102, 108, 12, 36, 5, 3]]\n"
     ]
    }
   ],
   "source": [
    "print(df[\"ConversaALimpa\"][0:5])\n",
    "print(tokens_conversa_a[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87d1016d-bbb1-4e93-b493-5d1b27243239",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_entrada_a = []\n",
    "for tokens in tokens_conversa_a:\n",
    "    tokens_entrada_a.append( tokens[1:-1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82a85408-df93-44a1-b021-1371d4dcaf58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1515, 39, 17, 5, 177],\n",
       " [34, 606, 39, 36, 556],\n",
       " [34, 159, 48, 250, 26, 491],\n",
       " [31, 173, 23, 39, 16, 5, 102],\n",
       " [103, 102, 108, 12, 36, 5]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_entrada_a[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b8df905-8a46-4122-a0d1-bcb64586372d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3725, 19)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_entrada_dados = pad_sequences( tokens_entrada_a, padding=\"pre\" )\n",
    "encoder_entrada_dados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e90f6d0b-7316-4e97-9a19-ebbda32222c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3725, 20)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_entrada_dados = pad_sequences( [tokens[0:-1] for tokens in tokens_conversa_a], padding=\"pre\" )\n",
    "decoder_entrada_dados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d7a538c-5c9f-4ae7-ad3d-e346810518ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3725, 20)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_saida_dados = pad_sequences( [tokens[1:] for tokens in tokens_conversa_b], padding=\"pre\" )\n",
    "decoder_saida_dados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fe865f4-59ac-4d36-83cc-0805f6f6e9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  34, 606,  39,  36, 556,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         34, 159,  48, 250,  26, 491,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  31,\n",
       "        173,  23,  39,  16,   5, 102,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        103, 102, 108,  12,  36,   5,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 103, 102,\n",
       "         48,  34,  18,  96,  70, 115,   3]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_saida_dados[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfacf46a-e3a8-42f5-b1cf-41731859527a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2527"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_PALAVRAS = len(vocabulario)\n",
    "NUM_PALAVRAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f0bdc9e-bf40-42cd-bbd7-9b24e8110ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_encoding_saida = CategoryEncoding(num_tokens=NUM_PALAVRAS, output_mode=\"one_hot\")\n",
    "decoder_saida_dados_onehot = category_encoding_saida( decoder_saida_dados ).numpy()\n",
    "decoder_saida_dados_onehot[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "346fe2f0-fa31-4314-b39c-cb82d37daa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dimens = 50\n",
    "lstm_nodes = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb602889-64ca-4c7f-b90a-70a3524db82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_layer = Input( (None, ) )\n",
    "encoder_embed_layer = Embedding( input_dim=(NUM_PALAVRAS), output_dim=embed_dimens, mask_zero=False)\n",
    "encoder_embed = encoder_embed_layer( encoder_input_layer )\n",
    "encoder_lstm_layer = LSTM( lstm_nodes, return_state = True )\n",
    "encoder_lstm_result, state_h, state_c = encoder_lstm_layer( encoder_embed )\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f703f70-6ae9-4b3a-9e1d-0c73f37e5cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_layer = Input( (None, ) )\n",
    "decoder_embed_layer = Embedding( input_dim=(NUM_PALAVRAS), output_dim=embed_dimens )\n",
    "decoder_embed = decoder_embed_layer( decoder_input_layer )\n",
    "decoder_lstm_layer = LSTM( lstm_nodes, return_state = True, return_sequences = True )\n",
    "decoder_lstm_result, _, _ = decoder_lstm_layer( decoder_embed, initial_state = encoder_states )\n",
    "decoder_saida_layer = Dense( NUM_PALAVRAS, activation=\"softmax\" )\n",
    "decoder_saida = decoder_saida_layer( decoder_lstm_result )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4f1bfb8-ef55-4303-9cce-d44ee5e61475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - Accuracy: 0.6183 - loss: 4.2983\n",
      "Epoch 2/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6239 - loss: 2.6634\n",
      "Epoch 3/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6239 - loss: 2.5650\n",
      "Epoch 4/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6239 - loss: 2.5126\n",
      "Epoch 5/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6498 - loss: 2.4628\n",
      "Epoch 6/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6702 - loss: 2.4067\n",
      "Epoch 7/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6713 - loss: 2.3595\n",
      "Epoch 8/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - Accuracy: 0.6730 - loss: 2.3184\n",
      "Epoch 9/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - Accuracy: 0.6736 - loss: 2.2820\n",
      "Epoch 10/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - Accuracy: 0.6738 - loss: 2.2542\n",
      "Epoch 11/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6740 - loss: 2.2252\n",
      "Epoch 12/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - Accuracy: 0.6751 - loss: 2.1987\n",
      "Epoch 13/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6759 - loss: 2.1795\n",
      "Epoch 14/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6767 - loss: 2.1593\n",
      "Epoch 15/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6776 - loss: 2.1450\n",
      "Epoch 16/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6779 - loss: 2.1328\n",
      "Epoch 17/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6782 - loss: 2.1217\n",
      "Epoch 18/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6782 - loss: 2.1122\n",
      "Epoch 19/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6786 - loss: 2.1008\n",
      "Epoch 20/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6793 - loss: 2.0913\n",
      "Epoch 21/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6793 - loss: 2.0842\n",
      "Epoch 22/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6797 - loss: 2.0746\n",
      "Epoch 23/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6802 - loss: 2.0658\n",
      "Epoch 24/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6804 - loss: 2.0576\n",
      "Epoch 25/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6812 - loss: 2.0464\n",
      "Epoch 26/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6810 - loss: 2.0417\n",
      "Epoch 27/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6814 - loss: 2.0314\n",
      "Epoch 28/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - Accuracy: 0.6819 - loss: 2.0239\n",
      "Epoch 29/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6818 - loss: 2.0149\n",
      "Epoch 30/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6820 - loss: 2.0068\n",
      "Epoch 31/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6816 - loss: 1.9990\n",
      "Epoch 32/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6827 - loss: 1.9921\n",
      "Epoch 33/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6824 - loss: 1.9849\n",
      "Epoch 34/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6830 - loss: 1.9747\n",
      "Epoch 35/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6835 - loss: 1.9665\n",
      "Epoch 36/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6831 - loss: 1.9612\n",
      "Epoch 37/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6834 - loss: 1.9550\n",
      "Epoch 38/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6836 - loss: 1.9460\n",
      "Epoch 39/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6837 - loss: 1.9413\n",
      "Epoch 40/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6839 - loss: 1.9351\n",
      "Epoch 41/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6843 - loss: 1.9265\n",
      "Epoch 42/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6846 - loss: 1.9220\n",
      "Epoch 43/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6846 - loss: 1.9146\n",
      "Epoch 44/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6850 - loss: 1.9098\n",
      "Epoch 45/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6854 - loss: 1.8997\n",
      "Epoch 46/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6855 - loss: 1.8942\n",
      "Epoch 47/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6860 - loss: 1.8865\n",
      "Epoch 48/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6858 - loss: 1.8809\n",
      "Epoch 49/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6866 - loss: 1.8728\n",
      "Epoch 50/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - Accuracy: 0.6867 - loss: 1.8675\n"
     ]
    }
   ],
   "source": [
    "modelo = Model( [encoder_input_layer, decoder_input_layer], decoder_saida )\n",
    "modelo.compile( optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"Accuracy\"])\n",
    "resultado = modelo.fit( [encoder_entrada_dados, decoder_entrada_dados], decoder_saida_dados_onehot, batch_size=32, epochs=50 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db62aefe-7b4a-41ff-8a4e-bbbbd76100f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_encoder = Model( encoder_input_layer, encoder_states )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e32f4bd-74de-444a-aca4-9b04d46cb36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_h = Input( (lstm_nodes, ) )\n",
    "decoder_state_c = Input( (lstm_nodes, ) )\n",
    "decoder_states_input = [decoder_state_h, decoder_state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2f7b32b-26b5-4576-8c83-b94e57c9b3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output, state_h2, state_c2 = decoder_lstm_layer( decoder_embed, initial_state = decoder_states_input )\n",
    "decoder_states_output = [state_h2, state_c2]\n",
    "decoder_saida2 = decoder_saida_layer( decoder_output )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c98ac736-9867-46c2-acfe-7a53053a4b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_decoder = Model( [decoder_input_layer] + decoder_states_input, [decoder_saida2] + decoder_states_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cc079c85-9c11-48e2-8800-3f308250d9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# texto = \"Hi how are you\"\n",
    "def gerador_textos( texto, max_palavras = 10):\n",
    "    tokens_sequence = tokenizer.texts_to_sequences( [texto] )\n",
    "    tokens_padded = pad_sequences( tokens_sequence, padding=\"pre\", maxlen=19 )\n",
    "    print(\"Tokens padded: \", tokens_padded)\n",
    "    state_values = modelo_encoder.predict( tokens_padded )\n",
    "    word_bos = vocabulario[\"<BOS>\"]\n",
    "    print(\"Word <BOS>: \", word_bos)\n",
    "    # <BOS> I am fine\n",
    "    # for i in range(max_palavras):\n",
    "    print(\"State Values: \", state_values )\n",
    "    sentenca_entrada = np.zeros( (1, 50) )\n",
    "    sentenca_entrada[0, 0] = word_bos\n",
    "    print(\"Sentenca Entrada: \", sentenca_entrada )\n",
    "    decoder_entrada = [sentenca_entrada] + state_values\n",
    "    print(\"Decoder Entrada: \", decoder_entrada )   \n",
    "    \n",
    "    decoder_saida, decoder_state_h, decoder_state_c = modelo_decoder.predict( decoder_entrada )\n",
    "    state_value = [decoder_state_h, decoder_state_c]\n",
    "    print(\"Decoder Saida shape: \", decoder_saida.shape )\n",
    "    print(\"Decoder Saida: \", decoder_saida )\n",
    "    indice_palavra = np.argmax( decoder_saida[0], axis=1 )\n",
    "    print(\"Indice Palavra: \", indice_palavra)\n",
    "    palavra = tokenizer.sequences_to_texts( [ indice_palavra] )\n",
    "    print( palavra )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1cc38320-34b1-45d4-ac52-1d4a981ad894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens padded:  [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1 39 17  5]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Word <BOS>:  2\n",
      "State Values:  [array([[-0.144234  ,  0.6844771 , -0.46837485, -0.48800692, -0.9711864 ,\n",
      "         0.6347825 ,  0.60839504,  0.6617092 ,  0.1702295 ,  0.53690505,\n",
      "         0.852619  , -0.98937786,  0.37499127,  0.19911115, -0.01993752,\n",
      "         0.10838546, -0.3492931 ,  0.57942295, -0.89838076,  0.59984505,\n",
      "         0.10657709,  0.45354944, -0.9625741 , -0.48585734, -0.7228261 ,\n",
      "        -0.4371291 , -0.582378  , -0.54629546, -0.40143165, -0.4400696 ,\n",
      "         0.771825  ,  0.31347132, -0.14726058,  0.7861715 , -0.25995025,\n",
      "        -0.4619554 , -0.29297984,  0.8029473 ,  0.5658165 , -0.35326254,\n",
      "         0.93717283,  0.95391536, -0.2662898 ,  0.32458076,  0.36328277,\n",
      "        -0.5029903 , -0.4770675 ,  0.843561  , -0.45848903, -0.36789563]],\n",
      "      dtype=float32), array([[-10.620183 ,  15.252989 ,  -7.1661344, -10.011179 ,  -5.861389 ,\n",
      "          9.030586 ,   9.891112 ,  13.148423 ,   9.275117 ,  11.005209 ,\n",
      "         11.127492 ,  -8.910027 ,   9.016188 ,   3.4925115,  -8.824751 ,\n",
      "          4.1604915,  -2.2154164,  11.282327 ,  -3.9622781,  11.908005 ,\n",
      "          8.887666 ,   8.254276 , -11.81301  , -10.449072 ,  -9.687411 ,\n",
      "         -9.704486 , -11.827913 , -11.058569 ,  -9.497774 , -11.144693 ,\n",
      "          4.6386614,   9.217542 ,  -9.3289995,   2.939087 , -12.071596 ,\n",
      "         -5.9383955,  -4.4402156,  18.880678 ,   9.89776  ,  -1.1805793,\n",
      "         10.094604 ,  18.971792 ,  -7.844403 ,   3.1460462,   7.2729645,\n",
      "         -7.6037173,  -7.559798 ,   3.9108932,  -3.839122 ,  -7.1817384]],\n",
      "      dtype=float32)]\n",
      "Sentenca Entrada:  [[2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]]\n",
      "Decoder Entrada:  [array([[2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.]]), array([[-0.144234  ,  0.6844771 , -0.46837485, -0.48800692, -0.9711864 ,\n",
      "         0.6347825 ,  0.60839504,  0.6617092 ,  0.1702295 ,  0.53690505,\n",
      "         0.852619  , -0.98937786,  0.37499127,  0.19911115, -0.01993752,\n",
      "         0.10838546, -0.3492931 ,  0.57942295, -0.89838076,  0.59984505,\n",
      "         0.10657709,  0.45354944, -0.9625741 , -0.48585734, -0.7228261 ,\n",
      "        -0.4371291 , -0.582378  , -0.54629546, -0.40143165, -0.4400696 ,\n",
      "         0.771825  ,  0.31347132, -0.14726058,  0.7861715 , -0.25995025,\n",
      "        -0.4619554 , -0.29297984,  0.8029473 ,  0.5658165 , -0.35326254,\n",
      "         0.93717283,  0.95391536, -0.2662898 ,  0.32458076,  0.36328277,\n",
      "        -0.5029903 , -0.4770675 ,  0.843561  , -0.45848903, -0.36789563]],\n",
      "      dtype=float32), array([[-10.620183 ,  15.252989 ,  -7.1661344, -10.011179 ,  -5.861389 ,\n",
      "          9.030586 ,   9.891112 ,  13.148423 ,   9.275117 ,  11.005209 ,\n",
      "         11.127492 ,  -8.910027 ,   9.016188 ,   3.4925115,  -8.824751 ,\n",
      "          4.1604915,  -2.2154164,  11.282327 ,  -3.9622781,  11.908005 ,\n",
      "          8.887666 ,   8.254276 , -11.81301  , -10.449072 ,  -9.687411 ,\n",
      "         -9.704486 , -11.827913 , -11.058569 ,  -9.497774 , -11.144693 ,\n",
      "          4.6386614,   9.217542 ,  -9.3289995,   2.939087 , -12.071596 ,\n",
      "         -5.9383955,  -4.4402156,  18.880678 ,   9.89776  ,  -1.1805793,\n",
      "         10.094604 ,  18.971792 ,  -7.844403 ,   3.1460462,   7.2729645,\n",
      "         -7.6037173,  -7.559798 ,   3.9108932,  -3.839122 ,  -7.1817384]],\n",
      "      dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Decoder Saida shape:  (1, 50, 2527)\n",
      "Decoder Saida:  [[[9.93264437e-01 7.29492466e-10 9.29046617e-10 ... 3.23384803e-08\n",
      "   3.82254450e-09 1.14670215e-07]\n",
      "  [9.98422980e-01 1.30435931e-11 1.42170043e-11 ... 7.27977234e-10\n",
      "   1.29381436e-10 1.86749838e-09]\n",
      "  [9.98456717e-01 1.25200154e-11 1.36233351e-11 ... 6.70799805e-10\n",
      "   1.22059932e-10 1.80778403e-09]\n",
      "  ...\n",
      "  [1.51001581e-03 1.53094373e-08 1.34368268e-08 ... 3.76539830e-08\n",
      "   5.61447814e-06 3.91568165e-06]\n",
      "  [1.51001266e-03 1.53094195e-08 1.34368117e-08 ... 3.76539369e-08\n",
      "   5.61448269e-06 3.91568119e-06]\n",
      "  [1.51000917e-03 1.53093840e-08 1.34368063e-08 ... 3.76539937e-08\n",
      "   5.61447996e-06 3.91567573e-06]]]\n",
      "Indice Palavra:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 6 8 8 8 5 5 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "['<OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> the a a a you you <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>']\n"
     ]
    }
   ],
   "source": [
    "texto = \"Hi how are you\"\n",
    "gerador_textos( texto )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6402a1-b304-4ae4-96d9-4f7fa8c8fc7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
