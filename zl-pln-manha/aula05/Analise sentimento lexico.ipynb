{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac02cee8-416e-4ba3-8913-1f1b3addd37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d446eced-1689-4028-8f6c-d4a33a4d571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07b155b4-0c8b-4d34-8214-57f227b8fd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3d5c1f5-122f-45a0-be3b-b7b1d0b8b946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b992a7e-0148-4ef8-b66f-c5b8e5f5bab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt_tab\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63701efa-a26b-410b-aa6f-e8d5d47f8861",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicionario : Dict[str, int] = {}\n",
    "with open(\"C:\\\\git\\\\dados\\\\nlp\\\\lexico_v3.0.txt\", \"r\", encoding=\"utf-8\") as lexico:\n",
    "    linha = \" \"\n",
    "    while linha != \"\":\n",
    "        linha = lexico.readline()\n",
    "        campos = linha.split(\",\")\n",
    "        if len(campos) >= 3: \n",
    "            chave = campos[0]\n",
    "            valor = int(campos[2])\n",
    "            dicionario[ chave ] = valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dad298d-82b6-4025-8b78-e8e68d356092",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"portuguese\"\n",
    "lista_stopwords = stopwords.words(language)\n",
    "lista_stopwords.extend(['a', 'o', '...', ',', '.', 'e', 'se', 'do', 'da'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcb4bcd6-1413-4894-8ef2-eab2874c6d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remover_stop_words( tokens : List[str] ) -> List[str]:\n",
    "    tokens_limpos = []\n",
    "    for token in tokens:\n",
    "        if token not in lista_stopwords:\n",
    "            tokens_limpos.append(token)\n",
    "    return tokens_limpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "929dd5c7-3961-4d3a-a133-aca0a610b1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analise_sentimento( tokens : List[str] ) -> int:\n",
    "    soma = 0\n",
    "    for token in tokens_limpos:\n",
    "        if token in dicionario:\n",
    "            valor = dicionario[token]\n",
    "            soma += valor\n",
    "            # print(f\"Token => {token}   Valor => {valor}\")\n",
    "    return soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "398af296-18fb-4c52-9e96-0d512fdbc6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5fe7a97d-5fbe-471d-95df-375de976b371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  -  hoje o dia está ensolarado e perfeito para um passeio no parque.  -  1\n",
      "0  -  infelizmente, o ônibus atrasou e cheguei tarde ao trabalho.  -  0\n",
      "0  -  o café na cozinha acabou e preciso comprar mais.  -  1\n",
      "1  -  recebi uma promoção no trabalho e estou muito feliz com a notícia!  -  1\n",
      "0  -  perdi meu celular e estou me sentindo frustrado.  -  0\n",
      "0  -  o jantar foi servido às sete da noite como de costume.  -  0\n",
      "1  -  passei no exame final e agora posso me formar.  -  0\n",
      "0  -  a chuva forte causou muitos transtornos no trânsito hoje.  -  1\n",
      "0  -  a reunião foi agendada para a próxima quarta-feira às três horas.  -  0\n",
      "1  -  ganhei um presente maravilhoso de aniversário da minha melhor amiga.  -  1\n",
      "0  -  briguei com um amigo e agora estou me sentindo triste.  -  0\n",
      "0  -  fui ao supermercado e comprei frutas e vegetais frescos.  -  1\n",
      "1  -  o show da minha banda favorita foi incrível e inesquecível.  -  1\n",
      "0  -  estou doente e preciso descansar em casa.  -  1\n",
      "0  -  o correio entregou a correspondência hoje pela manhã.  -  0\n",
      "1  -  recebi elogios do chefe pelo excelente trabalho realizado.  -  1\n",
      "0  -  o computador está lento e atrapalha meu trabalho.  -  0\n",
      "0  -  a previsão do tempo para amanhã é de sol e céu claro.  -  1\n",
      "1  -  a festa de casamento foi maravilhosa e todos se divertiram.  -  1\n",
      "0  -  a reunião foi cansativa e durou o dia todo.  -  0\n",
      "0  -  a entrega dos produtos ocorreu conforme o planejado.  -  0\n",
      "1  -  ganhei na loteria e estou muito animado!  -  1\n",
      "0  -  o carro quebrou no meio da estrada e foi um grande inconveniente.  -  0\n",
      "0  -  a biblioteca está aberta das nove às cinco todos os dias.  -  0\n",
      "1  -  passei um tempo agradável com minha família no final de semana.  -  1\n",
      "0  -  perdi meu voo e agora preciso esperar pelo próximo.  -  1\n",
      "0  -  o relatório foi enviado para revisão ontem à tarde.  -  0\n",
      "1  -  a performance no teatro foi incrível e cheia de emoção.  -  1\n",
      "0  -  estou decepcionado com o resultado do jogo de futebol.  -  0\n",
      "0  -  o ônibus passa a cada meia hora durante o dia.  -  0\n",
      "TP - (True Positive) 9\n",
      "TN - (True Negative) 14\n",
      "FP - (False Positive) 6\n",
      "FN - (False Negative) 1\n"
     ]
    }
   ],
   "source": [
    "nome_arquivo = \"C:\\\\git\\\\dados\\\\nlp\\\\analise_sentimento_portugues.csv\"\n",
    "with open(nome_arquivo, \"r\", encoding=\"utf-8\") as arquivo_frases:\n",
    "    lista_linhas = csv.reader( arquivo_frases, delimiter=\",\", quotechar='\"' )\n",
    "    for indice, linha in enumerate(lista_linhas):\n",
    "        if indice > 0:\n",
    "            sentimento_texto = linha[0]\n",
    "            sentimento_categorico = 1 if sentimento_texto == 'positivo' else 0\n",
    "            frase = linha[1]\n",
    "            texto = frase.lower()\n",
    "            tokens = tokenize.word_tokenize(texto, language='portuguese')\n",
    "            tokens_limpos = remover_stop_words( tokens )\n",
    "            resultado_continuo = analise_sentimento( tokens_limpos )\n",
    "            resultado_categorico = 1 if resultado_continuo > 0 else 0\n",
    "\n",
    "            if sentimento_categorico == 1 and resultado_categorico == 1:\n",
    "                TP += 1\n",
    "            elif sentimento_categorico == 0 and resultado_categorico == 0:\n",
    "                TN += 1\n",
    "            elif sentimento_categorico == 1 and resultado_categorico == 0:\n",
    "                FN += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "            \n",
    "            print(sentimento_categorico, \" - \", texto, \" - \", resultado_categorico)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f74e0efb-346c-45fd-acae-469f0d681399",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "16ab6fd3-db35-4aff-aba4-abd5854d960a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP - (True Positive) 9\n",
      "TN - (True Negative) 14\n",
      "FP - (False Positive) 6\n",
      "FN - (False Negative) 1\n",
      "Precision ==>  0.6\n",
      "Recall ==>  0.9\n",
      "Acuracia ==>  0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"TP - (True Positive)\", TP)\n",
    "print(\"TN - (True Negative)\", TN)\n",
    "print(\"FP - (False Positive)\", FP)\n",
    "print(\"FN - (False Negative)\", FN)\n",
    "\n",
    "print(\"Precision ==> \", precision)\n",
    "print(\"Recall ==> \", recall)\n",
    "print(\"Acuracia ==> \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90083195-4cee-4b34-9f47-690a08ddbbb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
