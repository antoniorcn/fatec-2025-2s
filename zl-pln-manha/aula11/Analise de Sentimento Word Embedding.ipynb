{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf4e26e5-53b4-4752-8ecc-a1c856e23268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45095931-5d0e-4925-b508-019e0d214467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62df2d49-c70e-44b1-af25-b1068809f2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e17d91c-fd65-428a-b32b-f68c408812ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eec8a9bb-56c4-480e-8a3b-cb013a2ba3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ceaf664-c7d4-47a3-b067-a87650148684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e18a9bc8-1025-453a-8eda-cac3aa32f703",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c01eb4b-4b27-41f3-bbb0-c6f835b018a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = KeyedVectors.load_word2vec_format(\"C:\\\\git\\\\dados\\\\nlp\\\\skip_s100\\\\skip_s100.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa3b617c-c2ea-4b84-9203-364c83e1d40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_en</th>\n",
       "      <th>text_pt</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>Este é um exemplo do motivo pelo qual a maiori...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Brass pictures movies is not a fitting word fo...</td>\n",
       "      <td>Filmes de fotos de latão não é uma palavra apr...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            text_en  \\\n",
       "0   1  Once again Mr. Costner has dragged out a movie...   \n",
       "1   2  This is an example of why the majority of acti...   \n",
       "2   3  First of all I hate those moronic rappers, who...   \n",
       "3   4  Not even the Beatles could write songs everyon...   \n",
       "4   5  Brass pictures movies is not a fitting word fo...   \n",
       "\n",
       "                                             text_pt sentiment  \n",
       "0  Mais uma vez, o Sr. Costner arrumou um filme p...       neg  \n",
       "1  Este é um exemplo do motivo pelo qual a maiori...       neg  \n",
       "2  Primeiro de tudo eu odeio esses raps imbecis, ...       neg  \n",
       "3  Nem mesmo os Beatles puderam escrever músicas ...       neg  \n",
       "4  Filmes de fotos de latão não é uma palavra apr...       neg  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:\\\\git\\\\dados\\\\nlp\\\\imdb-reviews-pt-br.csv\", encoding=\"utf-8\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "671f8946-17bb-4a5a-89a4-7d6c5bd74f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_en</th>\n",
       "      <th>text_pt</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, text_en, text_pt, sentiment]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna( inplace=True )\n",
    "df[df[\"text_pt\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23462abb-2c1c-4fd4-ad1b-91674f4714d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_en</th>\n",
       "      <th>text_pt</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>texto_limpo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
       "      <td>neg</td>\n",
       "      <td>mais uma vez o sr costner arrumou um filme por...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>Este é um exemplo do motivo pelo qual a maiori...</td>\n",
       "      <td>neg</td>\n",
       "      <td>este é um exemplo do motivo pelo qual a maiori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>primeiro de tudo eu odeio esses raps imbecis q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>nem mesmo os beatles puderam escrever músicas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Brass pictures movies is not a fitting word fo...</td>\n",
       "      <td>Filmes de fotos de latão não é uma palavra apr...</td>\n",
       "      <td>neg</td>\n",
       "      <td>filmes de fotos de latão não é uma palavra apr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            text_en  \\\n",
       "0   1  Once again Mr. Costner has dragged out a movie...   \n",
       "1   2  This is an example of why the majority of acti...   \n",
       "2   3  First of all I hate those moronic rappers, who...   \n",
       "3   4  Not even the Beatles could write songs everyon...   \n",
       "4   5  Brass pictures movies is not a fitting word fo...   \n",
       "\n",
       "                                             text_pt sentiment  \\\n",
       "0  Mais uma vez, o Sr. Costner arrumou um filme p...       neg   \n",
       "1  Este é um exemplo do motivo pelo qual a maiori...       neg   \n",
       "2  Primeiro de tudo eu odeio esses raps imbecis, ...       neg   \n",
       "3  Nem mesmo os Beatles puderam escrever músicas ...       neg   \n",
       "4  Filmes de fotos de latão não é uma palavra apr...       neg   \n",
       "\n",
       "                                         texto_limpo  \n",
       "0  mais uma vez o sr costner arrumou um filme por...  \n",
       "1  este é um exemplo do motivo pelo qual a maiori...  \n",
       "2  primeiro de tudo eu odeio esses raps imbecis q...  \n",
       "3  nem mesmo os beatles puderam escrever músicas ...  \n",
       "4  filmes de fotos de latão não é uma palavra apr...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a translation table to remove all punctuation\n",
    "translation_table = str.maketrans(\"\", \"\", punctuation)\n",
    "df[\"texto_limpo\"] = df[\"text_pt\"].str.translate(translation_table).str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65c4a54e-e94f-4217-bb3d-61d9a0e29b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_en</th>\n",
       "      <th>text_pt</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>texto_limpo</th>\n",
       "      <th>texto_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
       "      <td>neg</td>\n",
       "      <td>mais uma vez o sr costner arrumou um filme por...</td>\n",
       "      <td>[mais, uma, vez, o, sr, costner, arrumou, um, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>Este é um exemplo do motivo pelo qual a maiori...</td>\n",
       "      <td>neg</td>\n",
       "      <td>este é um exemplo do motivo pelo qual a maiori...</td>\n",
       "      <td>[este, é, um, exemplo, do, motivo, pelo, qual,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>primeiro de tudo eu odeio esses raps imbecis q...</td>\n",
       "      <td>[primeiro, de, tudo, eu, odeio, esses, raps, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>nem mesmo os beatles puderam escrever músicas ...</td>\n",
       "      <td>[nem, mesmo, os, beatles, puderam, escrever, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Brass pictures movies is not a fitting word fo...</td>\n",
       "      <td>Filmes de fotos de latão não é uma palavra apr...</td>\n",
       "      <td>neg</td>\n",
       "      <td>filmes de fotos de latão não é uma palavra apr...</td>\n",
       "      <td>[filmes, de, fotos, de, latão, não, é, uma, pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            text_en  \\\n",
       "0   1  Once again Mr. Costner has dragged out a movie...   \n",
       "1   2  This is an example of why the majority of acti...   \n",
       "2   3  First of all I hate those moronic rappers, who...   \n",
       "3   4  Not even the Beatles could write songs everyon...   \n",
       "4   5  Brass pictures movies is not a fitting word fo...   \n",
       "\n",
       "                                             text_pt sentiment  \\\n",
       "0  Mais uma vez, o Sr. Costner arrumou um filme p...       neg   \n",
       "1  Este é um exemplo do motivo pelo qual a maiori...       neg   \n",
       "2  Primeiro de tudo eu odeio esses raps imbecis, ...       neg   \n",
       "3  Nem mesmo os Beatles puderam escrever músicas ...       neg   \n",
       "4  Filmes de fotos de latão não é uma palavra apr...       neg   \n",
       "\n",
       "                                         texto_limpo  \\\n",
       "0  mais uma vez o sr costner arrumou um filme por...   \n",
       "1  este é um exemplo do motivo pelo qual a maiori...   \n",
       "2  primeiro de tudo eu odeio esses raps imbecis q...   \n",
       "3  nem mesmo os beatles puderam escrever músicas ...   \n",
       "4  filmes de fotos de latão não é uma palavra apr...   \n",
       "\n",
       "                                         texto_final  \n",
       "0  [mais, uma, vez, o, sr, costner, arrumou, um, ...  \n",
       "1  [este, é, um, exemplo, do, motivo, pelo, qual,...  \n",
       "2  [primeiro, de, tudo, eu, odeio, esses, raps, i...  \n",
       "3  [nem, mesmo, os, beatles, puderam, escrever, m...  \n",
       "4  [filmes, de, fotos, de, latão, não, é, uma, pa...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizar( texto ):\n",
    "    return word_tokenize(texto, language='portuguese')\n",
    "\n",
    "df[\"texto_final\"] = df[\"texto_limpo\"].apply( tokenizar )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "660ac518-cdce-4be6-9767-ba5ad0b86181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto com o maior numero de palavras:  953\n"
     ]
    }
   ],
   "source": [
    "dimensoes = 100\n",
    "max_palavras = 0\n",
    "\n",
    "for linha in df[\"texto_final\"]:\n",
    "    if len(linha) > max_palavras:\n",
    "        max_palavras = len(linha)\n",
    "print(\"Texto com o maior numero de palavras: \", max_palavras)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f1ccb79f-d4ba-4daf-a017-f310d067110f",
   "metadata": {},
   "source": [
    "[\n",
    "    [ ... 100 ],\n",
    "    [ ... 100 ],\n",
    "    [ ... 100 ],\n",
    "    [ ... 100 ],\n",
    "    [ ... 100 ],\n",
    "    [ ... 100 ],\n",
    "    [ ... 100 ],\n",
    "\n",
    "    [ ... 100 ] # Vazio,\n",
    "    [ ... 100 ] # Vazio,\n",
    "    [ ... 100 ] # Vazio,\n",
    "    ... 953    \n",
    "] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a556ee7-1c9f-458c-bf70-a287cbab01c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vetor_vazio = np.zeros((dimensoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e50ad7b4-986b-42fc-9ad0-d54a2674cbd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(953, 100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transformar_tokens_vetores( tokens ):\n",
    "    lista_vetores = []\n",
    "    for token in tokens:\n",
    "        vetor = vetor_vazio\n",
    "        try:\n",
    "            vetor = modelo[token]\n",
    "        except KeyError as err:\n",
    "            pass\n",
    "    \n",
    "        lista_vetores.append( vetor )\n",
    "    \n",
    "    for _ in range( max_palavras - len(lista_vetores) ):\n",
    "        lista_vetores.append( vetor_vazio )\n",
    "    return np.array(lista_vetores)\n",
    "\n",
    "transformar_tokens_vetores( df[\"texto_final\"][0] ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70f63bc3-c16a-4700-b9ca-b0a85d2fc917",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"X\"] = df[\"texto_final\"].apply( transformar_tokens_vetores )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4b162e8-7151-4bca-96b6-058efa514935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(953, 100)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"X\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea33f210-282d-4cb2-8ae9-dd223fb18229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anton\\AppData\\Local\\Temp\\ipykernel_19324\\574035808.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"Y\"] = df[\"sentiment\"].replace( {\"neg\": 0, \"pos\": 1} )\n"
     ]
    }
   ],
   "source": [
    "df[\"Y\"] = df[\"sentiment\"].replace( {\"neg\": 0, \"pos\": 1} ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f1decda-434b-40f1-8bff-e20ae8bee918",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df[\"Y\"]\n",
    "X = df[\"X\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6195fba8-92e0-4097-849b-bbd9f48ae561",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 100, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6c4216a-7a95-4081-b072-03f9e2dfb3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">95300</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">12,198,528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,064</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m95300\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │      \u001b[38;5;34m12,198,528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │           \u001b[38;5;34m2,064\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m17\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,200,609</span> (46.54 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,200,609\u001b[0m (46.54 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,200,609</span> (46.54 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,200,609\u001b[0m (46.54 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo = Sequential()\n",
    "modelo.add( Input( (max_palavras, dimensoes) ) )\n",
    "modelo.add( Flatten() )\n",
    "modelo.add( Dense( 128, activation=\"relu\" ) )\n",
    "modelo.add( Dense( 16, activation=\"relu\" ) )\n",
    "modelo.add( Dense( 1, activation=\"sigmoid\" ) )\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d97683a1-accf-4f7f-b1cc-f75f50da7b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.compile( optimizer = \"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db968ac1-a5c6-4eb6-b3e3-4515738b8451",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid dtype: object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m historico \u001b[38;5;241m=\u001b[39m modelo\u001b[38;5;241m.\u001b[39mfit( X_train, Y_train, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optree\\ops.py:752\u001b[0m, in \u001b[0;36mtree_map\u001b[1;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[0;32m    750\u001b[0m leaves, treespec \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39mflatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[0;32m    751\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treespec\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[1;32m--> 752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m treespec\u001b[38;5;241m.\u001b[39munflatten(\u001b[38;5;28mmap\u001b[39m(func, \u001b[38;5;241m*\u001b[39mflat_args))\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid dtype: object"
     ]
    }
   ],
   "source": [
    "historico = modelo.fit( X_train, Y_train, epochs = 10, batch_size = 128 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f512dd2d-7f0f-4065-bacc-1a0062c30d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.evaluate( X_test, Y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e45118d-e987-455c-ab6f-5bc50c87f44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vetorizador_predict = CountVectorizer( max_features = FEATURES, vocabulary = vocabulario, binary = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac9b521-b04d-41e7-85bd-57d6691a833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"I love music\"\n",
    "bow_predict = vetorizador_predict.fit_transform( [ texto ] )\n",
    "bow_predict_descompressed = pd.DataFrame.sparse.from_spmatrix( bow_predict , columns = vocabulario ).astype(float)\n",
    "\"positivo\" if modelo.predict( bow_predict_descompressed )[0][0] >= 0.5 else \"negativo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918c431c-20e6-4835-945b-305b97ae43f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
